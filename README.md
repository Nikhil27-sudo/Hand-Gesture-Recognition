# Hand-Gesture-Recognition
The main aim of this project is to make conversation between the deaf and dumb people easier. Created my own dataset. This model recognizes hand gestures from a live video sequence. Dataset is created by extracting the images of hand in grayscale using absolute background subtraction using OpenCV. The model converts the gestures into both text and speech. The project is dynamic as users can create their own custom gestures and then train the model before using those custom gestures.
